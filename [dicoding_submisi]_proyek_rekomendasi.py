# -*- coding: utf-8 -*-
"""[dicoding-submisi]-proyek_rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DDwVfSewNLXvr8X256975S-EpUwcdzYA

# Laporan Proyek Machine Learning - Leo Prangs Tobing
"""

# from google.colab import drive
# drive.mount('/content/drive')

"""## Project Overview

**Latar Belakang:**

Dalam era digital, jumlah buku yang tersedia secara daring terus meningkat dengan sangat pesat. Platform-platform seperti Amazon, Goodreads, atau sistem perpustakaan digital menyediakan katalog buku yang sangat luas, yang justru dapat menyulitkan pembaca dalam menemukan buku yang sesuai dengan preferensi atau minat mereka. Hal ini menciptakan kebutuhan akan sistem rekomendasi yang cerdas untuk membantu pengguna menavigasi pilihan yang sangat banyak.

Sistem rekomendasi telah menjadi komponen penting dalam meningkatkan **pengalaman pengguna** dan **personalisasi** dalam berbagai platform digital, termasuk dalam industri buku. Dalam konteks ini, sistem rekomendasi dapat memberikan saran buku yang relevan berdasarkan minat pembaca, riwayat interaksi, atau penilaian (rating) mereka terhadap buku sebelumnya. Selain membantu pengguna menemukan buku yang sesuai, sistem ini juga berperan penting dalam meningkatkan **keterlibatan pengguna**, **retensi pembaca**, dan bahkan **peningkatan penjualan** atau sirkulasi buku di platform penyedia layanan.

Dua pendekatan umum yang sering digunakan dalam pengembangan sistem rekomendasi adalah **Content-Based Filtering (CBF)** dan **Collaborative Filtering (CF)**. Content-Based Filtering bekerja dengan membandingkan fitur-fitur konten antar buku (seperti genre, penulis, atau kata kunci deskripsi), sedangkan Collaborative Filtering menggunakan pola interaksi pengguna lain yang memiliki preferensi serupa. Menurut Aggarwal (2016), kedua pendekatan ini merupakan dasar dari kebanyakan sistem rekomendasi modern. Di sisi lain, Jannach et al. (2010) menekankan pentingnya sistem rekomendasi dalam mendukung eksplorasi item dalam katalog besar, termasuk dalam konteks literatur atau buku.

**Referensi:**

- Aggarwal, C. C. (2016). *Recommender Systems: The Textbook*. Springer.
- Jannach, D., Adomavicius, G., Tuzhilin, A., & Kantor, P. (2010). *Recommender Systems – Challenges, Insights and Research Opportunities*. ACM Transactions on Intelligent Systems and Technology (TIST), 1(1), 1–38.

## Business Understanding

**Problem Statements:**

- Banyak pengguna kesulitan menemukan buku yang sesuai dengan minat mereka karena banyaknya pilihan.
- Rekomendasi buku yang ditampilkan sering kali tidak dipersonalisasi berdasarkan preferensi pengguna sebelumnya.
- Tidak adanya sistem pendukung keputusan yang membantu pengguna mengeksplorasi buku-buku baru yang relevan dengan preferensi mereka.

**Project Goals:**

- Mengembangkan sistem rekomendasi buku yang dapat memberikan saran bacaan personal berdasarkan data riwayat rating pengguna.
- Membandingkan dua pendekatan sistem rekomendasi, yaitu Content-Based Filtering dan Collaborative Filtering, untuk mengevaluasi mana yang lebih efektif dalam memberikan rekomendasi yang relevan.
- Mengukur performa model menggunakan metrik evaluasi seperti **Precision** dan **Recall** berdasarkan buku-buku yang paling disukai (rating tertinggi) oleh pengguna.

**Solution Approach:**

- **Content-Based Filtering (CBF):** Rekomendasi diberikan berdasarkan kesamaan konten antar buku, seperti kesamaan tag, genre, atau fitur tekstual lainnya.
- **Collaborative Filtering (CF):** Rekomendasi dibuat berdasarkan perilaku dan pola rating dari pengguna lain yang memiliki preferensi serupa.
- Untuk evaluasi, dilakukan split data berdasarkan buku-buku dengan rating tertinggi sebagai *ground truth*, dan sistem akan diuji apakah mampu merekomendasikan buku tersebut kembali dalam top-N hasil.
- Metrik yang digunakan untuk mengevaluasi performa adalah **Precision** dan **Recall**, untuk mengukur seberapa relevan dan lengkap rekomendasi yang dihasilkan oleh sistem.

## Data Understanding

### Load Data

Siapkan semua library yang diperlukan proyek & load dataset. Dataset yang digunakan adalah **Book-Crossing: User review ratings** dari [Kaggle](https://www.kaggle.com/datasets/ruchi798/bookcrossing-dataset), dengan file yang digunakan adalah `Preprocessed_data.csv` (kombinasi informasi user, buku dan rating)
"""

# # buka block kode ini, downgrage numpy==2.0.2 jadi versi yang kompatible dgn lingkunan scikit-suprise di GColab
# # restar ulang sesi, lalu comment kembali kode setelah selesai
# !pip install numpy==1.24.4 --force-reinstall

# !pip install -qq scikit-surprise==1.1.4
# !pip install -qq kagglehub

# load & EDA
import kagglehub
import pandas as pd

# Preprocesasing
import numpy as np # ajust dtype
from collections import defaultdict
from sklearn.feature_extraction.text import TfidfVectorizer

# modelling
from sklearn.metrics.pairwise import cosine_similarity
from surprise import SVD, Dataset, Reader

# Untuk .py file (run in terminal)
from IPython.display import display

# Inferensi
import random

# Download latest version
path = kagglehub.dataset_download("ruchi798/bookcrossing-dataset")

print("Path to dataset files:", path)

df = pd.read_csv(f"{path}/Books Data with Category Language and Summary/Preprocessed_data.csv")
print("df.shape", df.shape)
display(df.head())

"""**Insight:**

Terdapat **1.031.175 baris** data, dengan 19 kolom:

| No. | Kolom              | Deskripsi                                                                 |
|-----|--------------------|---------------------------------------------------------------------------|
| 1   | `Unnamed: 0`       | Indeks baris yang dihasilkan secara otomatis saat menyimpan file (bisa diabaikan). |
| 2   | `user_id`          | ID unik dari pengguna. Digunakan untuk mengidentifikasi user secara individual. |
| 3   | `location`         | Lokasi tempat tinggal pengguna dalam format "kota, provinsi, negara". |
| 4   | `age`              | Usia pengguna (dalam tahun). Tipe numerik. |
| 5   | `isbn`             | Nomor ISBN sebagai pengenal unik buku. |
| 6   | `rating`           | Nilai rating yang diberikan pengguna terhadap buku. Biasanya dalam skala 0–10. |
| 7   | `book_title`       | Judul lengkap dari buku. |
| 8   | `book_author`      | Nama penulis buku. |
| 9   | `year_of_publication` | Tahun buku tersebut diterbitkan. |
| 10  | `publisher`        | Nama penerbit buku. |
| 11  | `img_s`            | URL ke gambar sampul buku berukuran kecil (small). |
| 12  | `img_m`            | URL ke gambar sampul buku berukuran sedang (medium). |
| 13  | `img_l`            | URL ke gambar sampul buku berukuran besar (large). |
| 14  | `Summary`          | Ringkasan atau deskripsi isi buku. Dapat digunakan sebagai fitur teks dalam sistem rekomendasi. |
| 15  | `Language`         | Bahasa yang digunakan dalam buku (contoh: `en` untuk English). |
| 16  | `Category`         | Kategori atau genre buku, biasanya dalam bentuk list string (misalnya: `['Social Science']`). |
| 17  | `city`             | Kota asal pengguna (dipecah dari kolom `location`). |
| 18  | `state`            | Negara bagian atau provinsi asal pengguna (dipecah dari kolom `location`). |
| 19  | `country`          | Negara asal pengguna (dipecah dari kolom `location`). |

### EDA
Beberapa analisis yang punya insight penting
"""

# Melihat jumlah user dan jumlah buku
print(f"{df['user_id'].nunique()} user, {df['isbn'].nunique()} buku")
print('\n---------- Change DType ---------')
display(df.info())
display(df[df['age'] == 5].head(3))
display(df[df['year_of_publication'] == 1376])

print('\n--------- Null Values ---------')
print('df.isna().sum():\n',df.isna().sum())

print('\n--------- Outliers ---------')
display('df.describe().T: ',df.describe().T)


print('\n--------- Invalid Values ---------')
for col in ['age', 'Language', 'Category']: # kolom kategori atau ordinal yang perlu diperiksa
    print(f"{col}: {df[col].unique().tolist()}")
display(df[df['Summary'] == '9'].head(3))

"""**Insight:**
- 92.107 user, 270.170 buku
- **change Dtype:** `age` & `year_of_publication` dapat diubah ke **int**
- **null value:** `book_author` = 1, `city` = 14k, `state` = 22k, `country` = 35k
- **number distribution:**
  - **outliers**: `age` diusia 5 untuk rata-rata pembaca usia 36 tahun, dan `year_of_publication` yang punya tahun 1376 untuk rata rata tahun 1995.
  - 50% data `rating` bernilai 0, mungkin karena: Rating default (belum memberikan penilaian) atau pengguna tidak suka bukunya.
- **Invalid Value**:
  - nilai `34.74389988072476` pade `age` perlu dibulatkan
  - nilai `9` pada `Summary`, `Language`, dan `Category` bisa berarti placeholder untuk metadata buku yang tidak perlu ditampilkan kembali setelah kemunculan pertama

Catatan: Hasil insight hanya untuk pemahaman umum, berguna atau tidak tergantung apakah kolom dipakai untuk modelling.

## Data Preparation

### Pembersihan
Hapus kolom tidak berguna, ubah tipe data, handle null & ubah data invalid.
"""

df2 = df.copy(deep=True) # Berganti ke versi 2 (lebih bersih)

# --- CLEANING ---
# Hapus 7 kolom yang tidak diperlukan
df2 = df2.drop(columns=['Unnamed: 0', 'img_s', 'img_m', 'img_l', 'city', 'state', 'country', 'Summary'])

# ubah tipe data
df2['age'] = df2['age'].astype(int)
df2['year_of_publication'] = df2['year_of_publication'].astype(int)

# isi nilai null
df2['book_author'] = df2['book_author'].astype(str).fillna('')

# ubah data invalid
df2['Language'] = df2['Language'].replace('9', '', regex=False)
df2['Category'] = df2['Category'].replace('9', '', regex=False)

df2.shape

"""Walau dapat dipakai untuk model CBF, Kolom `Summary` dihapus karena dapat menimbulkan noise.

### Sampling
Ambil irisan dari masing-masing top 500 User dan Buku (untuk performa).
"""

# --- SAMPLING ---
# ambil 500 user_id yang paling sering muncul
top_500_users = df['user_id'].value_counts().nlargest(500).index.tolist()

# ambil 500 isbn yang paling sering muncul
top_500_isbns = df['isbn'].value_counts().nlargest(500).index.tolist()

print("Top 500 User IDs:")
print(top_500_users[:10]) # print beberapa contoh
print("\nTop 500 ISBNs:")
print(top_500_isbns[:10]) # print beberapa contoh

# Filter the DataFrame to include only interactions from the top 500 users
df_filtered_users = df2[df2['user_id'].isin(top_500_users)]

# Further filter the result to include only interactions with the top 500 ISBNs
df2 = df_filtered_users[df_filtered_users['isbn'].isin(top_500_isbns)].reset_index(drop=True)

df2.shape

"""Dataset hasil filter: **~29.000** baris.

### Pembuatan Data untuk Model

#### `df_book` (CBF)
Versi unik buku + combined_features (gabungan title, author, publisher, language, category) untuk CBF.
"""

df_book = df2.copy(deep=True)

# ambil nilai book unik berdasarka isbn
df_book = df_book.drop_duplicates('isbn')

# Gabungkan kolom-kolom teks (nilai pengelompokkan dan kepemilikan)
df_book['combined_features'] = df_book[['book_title', 'book_author', 'publisher', 'Language', 'Category']].agg(' '.join, axis=1)

pd.set_option('display.max_colwidth', None) # Jangan potong isi kolom
pd.set_option('display.width', None) # Biarkan lebar menyesuaikan layar
pd.set_option('display.max_columns', None) # Tampilkan semua kolom jika banyak

# sederhanakan tabel
df_book = df_book[['isbn', 'book_title', 'combined_features']].reset_index(drop=True)

print(df_book.shape)
df_book.sample(10)

"""- Setiap fitur penting digabung karena TF-IDF Butuh Representasi Teks Tunggal

#### `train_data` & `test_ground_truth`
- Buat ground truth: Ambil hanya buku dengan rating >= 5.
- Pisahkan test dan train: Gunakan 1 buku terakhir dari user sebagai test, sisanya sebagai train.
- Model Content-Based Filtering (CBF) yang menggunakan kemiripan antar fitur dievaluasi menggunakan data train dan test ini.
"""

# --- Filter rating >= 5 (threshold minimum rating yang dianggap relevan (Disukai)) ---
liked = df2[df2["rating"] >= 5]

# --- Mapping user -> daftar (isbn, rating) ---
user_liked_books = defaultdict(list)

for _, row in liked.iterrows():
    user_liked_books[row["user_id"]].append((row["isbn"], row["rating"]))

# --- Split ke train dan test (test: buku dengan rating tertinggi) ---
train_data = []
test_ground_truth = {}

for user, books in user_liked_books.items():
    if len(books) < 2:
        print("ada user dengan data terlalu sedikit di-skip")
        continue  # user dengan data terlalu sedikit di-skip

    # Urutkan buku berdasarkan rating (tinggi ke rendah)
    books_sorted = sorted(books, key=lambda x: x[1], reverse=True)
    highest_rating = books_sorted[0][1]

    # Ambil semua buku dengan rating tertinggi sebagai test
    test_books = [isbn for isbn, rating in books_sorted if rating == highest_rating]

    # Sisanya masuk ke data latih
    train_books = [isbn for isbn, rating in books_sorted if rating < highest_rating]

    if len(test_books) > 0 and len(train_books) > 0:
        test_ground_truth[user] = test_books
        train_data.extend([(user, isbn) for isbn in train_books])

print(user_liked_books)

print(train_data[:5])
print(test_ground_truth)

"""#### `train_df_cf` (CF)
- Digunakan untuk model Collaborative Filtering.
- Model CF yang menggunakan pola user book dari user lain yang serupa (dari train data) dan merekomendasikannya, hasilnya akan dievaluasi dengan data testing.
"""

# Buat DataFrame dari train_data
train_df_cf = pd.DataFrame(train_data, columns=["user_id", "isbn"])
train_df_cf["rating"] = 5  # Karena semua data ini adalah rating >= 5 (menyederhanakan model)

"""## Modelling

### Content-Based Filtering (CBF)

- Membandingkan kemiripan antar buku berdasarkan konten atau metadata-nya.
- Fitur-fitur dalam string (`combined_features`)  ditransformasikan ke dalam bentuk vektor menggunakan **TF-IDF (Term Frequency - Inverse Document Frequency)**.
- Kemiripan antar buku dihitung menggunakan **cosine similarity** antar vektor.
"""

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english')

# Transformasikan ke bentuk numerik
tfidf_matrix = tfidf.fit_transform(df_book['combined_features'])

# Ukuran matriks (baris: isbn, kolom: kata unik dari combined_features)
print(f"TF-IDF matrix shape: {tfidf_matrix.shape}")

# Contoh kata-kata (fitur) yang dihasilkan
feature_names = tfidf.get_feature_names_out()
print(f"Contoh fitur: {feature_names[:20]}")

"""- Didapatkan matriks TF-IDF dengan ukuran 500 ✖ 230"""

# --- Mapping ISBN ke indeks yang dipakai dalam model tf-idf matrix ---
isbn_to_index = {isbn: idx for idx, isbn in enumerate(df_book['isbn'])}
index_to_isbn = {v: k for k, v in isbn_to_index.items()}

def get_similar_books(isbn, top_n=10):
    if isbn not in isbn_to_index:
        return []
    idx = isbn_to_index[isbn]
    cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()
    similar_indices = cosine_sim.argsort()[::-1][1:top_n+1]
    return [index_to_isbn[i] for i in similar_indices]

# Ambil semua buku yang disukai user dari train
user_liked_books = defaultdict(list)
for user, isbn in train_data: # Data Uji
    user_liked_books[user].append(isbn)

# Buat prediksi rekomendasi berdasarkan kesamaan buku yang disukai
predictions_cbf = {}
for user, liked_books in user_liked_books.items():
    recs = []
    for b in liked_books:
        recs.extend(get_similar_books(b, top_n=5))  # bisa ubah top_n
    # Filter duplikat
    predictions_cbf[user] = list(dict.fromkeys(recs))[:10]

print("predictions_cbf (CBF):", predictions_cbf)
print("Target Ground Truth:", test_ground_truth)

"""Prediction kedua model dan Target Ground Truth akan dibandingkan untuk mendapatkan skor evaluasi

### Collaborative Filtering (CF) – SVD
- Berdasarkan pola rating yang diberikan oleh pengguna lain.
- Menggunakan **SVD (Singular Value Decomposition)** dari library `surprise` untuk memfaktorkan matriks user-item menjadi representasi laten.
- Model belajar dari `train_df_cf` (interaksi user-book dengan rating 5).

Dengan trainset yang sudah disiapkan matriks (user, book, rating), metode Singular Value Decomposition dapat dilakukan.
"""

# Buat dataset surprise
reader = Reader(rating_scale=(1, 5)) # memberi tahu bahwa semua rating berada pada skala 1 hingga 5
train_data_surp = Dataset.load_from_df(train_df_cf[["user_id", "isbn", "rating"]], reader) # menjadi objek dataset yang bisa digunakan oleh library surprise
trainset = train_data_surp.build_full_trainset() # trainset adalah objek yang berisi semua data pelatihan yang siap digunakan oleh algoritma surprise

model_cf = SVD()
model_cf.fit(trainset)

def get_top_n(model, trainset, all_isbns, users, n=10):
    top_n = defaultdict(list)

    for user in users:
        try:
            inner_uid = trainset.to_inner_uid(user)
        except ValueError:
            continue  # user tidak dikenal di trainset

        seen_books = set([isbn for (u, isbn) in train_data if u == user])
        unseen_books = [isbn for isbn in all_isbns if isbn not in seen_books]

        predictions = [model.predict(user, isbn) for isbn in unseen_books]
        predictions.sort(key=lambda x: x.est, reverse=True)

        top_n[user] = [pred.iid for pred in predictions[:n]]

    return top_n

# ISBN unik
all_isbns = df2["isbn"].unique()
users_to_eval = list(test_ground_truth.keys())

# Buat prediksi rekomendasi
predictions_cf = get_top_n(model_cf, trainset, all_isbns, users_to_eval, n=10)
print("Predictions (CF): ", predictions_cf)
print("Target Ground Truth:", test_ground_truth)

"""## Evaluation

### Metrik Precision & Recall
"""

# Evaluasi
def evaluate_precision_recall(predictions, ground_truth):
    precisions, recalls = [], []

    for user in ground_truth:
        if user not in predictions:
            continue
        true_items = set(ground_truth[user])
        pred_items = set(predictions[user])
        tp = len(true_items & pred_items)

        precision = tp / len(pred_items) if pred_items else 0
        recall = tp / len(true_items) if true_items else 0

        precisions.append(precision)
        recalls.append(recall)

    avg_precision = sum(precisions) / len(precisions) if precisions else 0
    avg_recall = sum(recalls) / len(recalls) if recalls else 0
    return avg_precision, avg_recall

"""### Content-Based Filtering (CBF)
Evaluasi dengan precision & recall
"""

precision_cbf, recall_cbf = evaluate_precision_recall(predictions_cbf, test_ground_truth) # bandingkan hasil prediksi dan target
print("Predictions:", predictions_cbf)
print("Ground Truth:", test_ground_truth)
print(f"Precision (CBF): {precision_cbf:.4f}, Recall (CBF): {recall_cbf:.4f}")

"""**Interpretasi:**
- `Precision = 0.0221 (≈ 2.21%)` Dari seluruh buku yang direkomendasikan, hanya 2.21% yang benar-benar disukai oleh user.
- `Recall = 0.0632 (≈ 6.32%)` Dari semua buku yang seharusnya direkomendasikan (user_liked_books), hanya 6.32% yang berhasil diprediksi.
- Precision tinggi → model merekomendasikan buku yang benar-benar disukai pengguna.
- Recall tinggi → model berhasil menangkap sebagian besar buku yang disukai pengguna.
- Jika kedua nilai rendah, kemungkinan:
 - Deskripsi buku tidak cukup informatif.
 - Kesamaan konten (TF-IDF) tidak mencerminkan preferensi pengguna.
 - Perlu pendekatan lain: collaborative filtering, matrix factorization, dll.

### Collaborative Filtering (CF)
Evaluasi precision dan recall
"""

precision_cf, recall_cf = evaluate_precision_recall(predictions_cf, test_ground_truth) # bandingkan hasil prediksi dan target
print("Predictions:", predictions_cf)
print("Ground Truth:", test_ground_truth)
print(f"Precision (CF): {precision_cf:.4f}, Recall (CF): {recall_cf:.4f}")

"""**Inferensi:**
- `Precision = 0.0128 (~1.28%)` Dari seluruh rekomendasi yang diberikan oleh model ke pengguna, hanya 1.28% yang benar-benar sesuai dengan selera mereka (buku dengan rating tertinggi).
- `Recall = 0.0367 (~3.67%)` Dari semua buku favorit (yang pengguna beri rating tertinggi), hanya 3.67% yang berhasil direkomendasikan oleh model.

### Kesimpulan

| Model                     | Precision | Recall  |
|--------------------------|-----------|---------|
| Content-Based Filtering  | 0.0221    | 0.0632  |
| Collaborative Filtering  | 0.0128    | 0.0367  |

- CBF unggul dalam precision dan recall dibandingkan CF.
- CBF lebih baik dalam merekomendasikan buku yang benar-benar disukai (rating tinggi).
- Namun, kedua model masih memiliki akurasi rendah secara keseluruhan, yang menunjukkan perlunya peningkatan atau pendekatan hybrid.

### Contoh Output per User
Mengambil data user random dan kedua model akan mengembalikan list Rekomendasi nya masing masing.
"""

sample_user = random.choice(list(test_ground_truth.keys()))
print(f"\nUser: {sample_user}")
print(f"Ground Truth (buku paling disukai): {test_ground_truth[sample_user]}")
print(f"Rekomendasi Top-10 (CBF): {predictions_cbf.get(sample_user, [])}")
print(f"Rekomendasi Top-10 (CF): {predictions_cf.get(sample_user, [])}")